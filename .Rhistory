# Calculer la distance entre le SNP actuel et le SNP précédent
# shift() décale la colonne de 1, fill=0 pour le premier SNP
data_subset[, distance_to_prev := Position - shift(Position, fill = data_subset$Position[1])]
# Démarrer un nouveau cluster si la distance dépasse le seuil
data_subset[, new_cluster := distance_to_prev > DISTANCE_THRESHOLD_BP]
# Cumulativement sommer les 'new_cluster' pour obtenir un identifiant unique par bloc
data_subset[, Cluster_ID := cumsum(new_cluster)]
return(data_subset)
}
# Appliquer la fonction pour chaque chromosome
clustered_snps <- important_snps[, identify_clusters(.SD), by = Chromosome]
# Distance maximale entre deux SNP consécutifs pour former un cluster (ex: 100 kb)
DISTANCE_THRESHOLD_BP <- 100000
# Créer un identifiant de cluster initial
important_snps[, Cluster_ID := 0]
# Fonction pour identifier les blocs par chromosome
# Fonction corrigée pour retourner un data.table avec les nouvelles colonnes
identify_clusters_corrected <- function(data_subset) {
# S'assurer que les SNP sont triés par position
setorder(data_subset, Position)
# Calculer la distance entre le SNP actuel et le SNP précédent
distance_to_prev <- data_subset$Position - shift(data_subset$Position, fill = data_subset$Position[1])
# Démarrer un nouveau cluster si la distance dépasse le seuil
new_cluster <- distance_to_prev > DISTANCE_THRESHOLD_BP
# Cumulativement sommer les 'new_cluster' pour obtenir un identifiant unique par bloc
Cluster_ID <- cumsum(new_cluster)
# Important : Retourner toutes les colonnes nécessaires (VIP_mean et l'ID)
return(data.table(
VIP_mean = data_subset$VIP_mean,
Position = data_subset$Position,
Cluster_ID = Cluster_ID
))
}
# --- Remplacement de l'appel à la fonction ---
# Récupérer les nouvelles colonnes Cluster_ID et les joindre à important_snps
# On utilise .I pour s'assurer que l'ordre des lignes est préservé lors de la fusion
cluster_results <- important_snps[, identify_clusters_corrected(.SD), by = Chromosome]
# La table 'cluster_results' contient maintenant les colonnes nécessaires pour l'étape 3
# Vous n'avez pas besoin de l'étape intermédiaire 'clustered_snps'.
# Appliquer la fonction pour chaque chromosome
clustered_snps <- important_snps[, identify_clusters(.SD), by = Chromosome]
important_snps
# Utilisation de la table vip_loc qui contient VIP_mean, Chromosome et Position
VIP_THRESHOLD <- 2.0
# Filtrer les SNP dont le VIP moyen est supérieur au seuil
important_snps <- vip_loc[VIP_mean > VIP_THRESHOLD]
cat(paste("Nombre de SNP conservés après le filtrage VIP >", VIP_THRESHOLD, ":", nrow(important_snps), "\n"))
important_snps
# Utilisation de la table vip_loc qui contient VIP_mean, Chromosome et Position
VIP_THRESHOLD <- 3.0
# Filtrer les SNP dont le VIP moyen est supérieur au seuil
important_snps <- vip_loc[VIP_mean > VIP_THRESHOLD]
cat(paste("Nombre de SNP conservés après le filtrage VIP >", VIP_THRESHOLD, ":", nrow(important_snps), "\n"))
important_snps
library(data.table)
library(ggplot2)
library(caret)
library(nnet)
library(pls)
library(snpStats)
library(data.table)
library(ggplot2)
library(caret)
library(nnet)
library(pls)
library(snpStats)
library(pls)
library(caret)
library(data.table)
library(parallel)
library(doParallel)
library(data.table)
library(ggplot2)
library(nnet)
library(pls)
library(FactoMineR)
library(qqman)
library(mixOmics)
library(glmnet)
library(pls)
library(caret)
library(data.table)
library(parallel)
library(doParallel)
library(data.table)
library(ggplot2)
library(nnet)
library(pls)
library(FactoMineR)
library(qqman)
library(mixOmics)
library(glmnet)
data(Phenotype)
data(Genomic)
data("localisation")
pheno <- as.data.table(Phenotype)
loc_df <- as.data.table(localisation)
geno <- as.data.table(Genomic)
geno[, ID := rownames(Genomic)]
pheno[, ID := rownames(Phenotype)]
merged <- merge(pheno, loc_df[, list(Population, ID)], by = "ID")
merged <- merge(merged, geno, by = "ID")
# Y : Phénotype, X : Matrice de SNP
y <- merged$CIRC2009
y <- as.numeric(y)
X <- as.matrix(merged[, 23:ncol(merged)])
SAVE_DIR <- "results_random_VIP_PLS"
# tous fichiers de performance
perf_files <- list.files(path = SAVE_DIR, pattern = "^perf_s5000.*\\.rds$", full.names = TRUE)
results_perf <- rbindlist(lapply(perf_files, readRDS))
# tous les fichiers VIP
vip_files <- list.files(path = SAVE_DIR, pattern = "^vip_s5000.*\\.rds$", full.names = TRUE)
results_vip <- rbindlist(lapply(vip_files, readRDS))
vip_mean <- results_vip[, .(VIP_mean = mean(VIP, na.rm = TRUE),
SNP_count = .N,
SNP_max_size = max(subset_size)),
by = SNP]
VIP_THRESHOLD <- 3.0
# Filtrer les SNP sur le VIP moyen
important_snps <- vip_mean[VIP_mean > VIP_THRESHOLD]
important_snps
vip_mean
X_sub <- X[,vip_mean$SNP]
set.seed(123)
K_outer <- 5
K_inner <- 5
outer_folds <- createFolds(y, k = K_outer, returnTrain = TRUE)
results <- data.frame(
outer_fold = integer(),
lambda_opt = numeric(),
R2 = numeric(),
RMSE = numeric()
)
for (f in 1:K_outer) {
print(f)
# Split externe
train_idx <- outer_folds[[f]]
test_idx  <- setdiff(seq_along(y), train_idx)
X_train <- X_sub[train_idx, ]
X_test  <- X_sub[test_idx, ]
y_train <- y[train_idx]
y_test  <- y[test_idx]
# CV interne pour le choix du lambda
cv_inner <- cv.glmnet(
x = X_train,
y = y_train,
alpha = 0,                # =0 pour pénalité Ridge ;)
nfolds = K_inner,
standardize = TRUE
)
lambda_opt <- cv_inner$lambda.min
# Modèle final
ridge_final <- glmnet(
x = X_train,
y = y_train,
alpha = 0,
lambda = lambda_opt,
standardize = TRUE
)
# Performances
y_pred <- as.vector(predict(ridge_final, newx = X_test))
R2_test <- cor(y_test, y_pred)^2
RMSE_test <- sqrt(mean((y_test - y_pred)^2))
results <- rbind(results, data.frame(
outer_fold = f,
lambda_opt = lambda_opt,
R2 = R2_test,
RMSE = RMSE_test
))
}
summary(results$R2)
mean(results$R2)
boxplot(results$R2)
SAVE_DIR <- "results_random_VIP_PLS"
# tous fichiers de performance
perf_files <- list.files(path = SAVE_DIR, pattern = "^perf_s5000.*\\.rds$", full.names = TRUE)
results_perf <- rbindlist(lapply(perf_files, readRDS))
# tous les fichiers VIP
vip_files <- list.files(path = SAVE_DIR, pattern = "^vip_s5000.*\\.rds$", full.names = TRUE)
results_vip <- rbindlist(lapply(vip_files, readRDS))
N_ITER_TOTAL <- results_perf[, max(iter)] * length(unique(results_perf$subset_size))
# Nombre total d'apparitions (pour 5 iters de 100 et 5 iters de 500)
vip_stability <- results_vip[, .(VIP_mean = mean(VIP, na.rm = TRUE),
VIP_sd = sd(VIP, na.rm = TRUE),
N_Observations = .N),
by = SNP]
# Le nombre max d'observations pour un SNP est :
# N_Folds (5) * N_Iterations (5) * N_Taille_Subsets (2) = 50 observations max
# Étude de la variabilité : VIP moyen vs Écart-type du VIP
ggplot(vip_stability, aes(x = VIP_mean, y = VIP_sd, size = N_Observations)) +
geom_point(alpha = 0.6) +
geom_text(data = vip_stability[order(-VIP_mean)][1:5],
aes(label = SNP), vjust = -1, color = "red") +
labs(title = "Stabilité du Score VIP : Moyenne vs Écart-Type",
x = "VIP Moyen (Robustesse)",
y = "Écart-type du VIP (Stabilité)",
size = "Fréquence d'Observation") +
theme_minimal()
vip_mean <- results_vip[, .(VIP_mean = mean(VIP, na.rm = TRUE),
SNP_count = .N,
SNP_max_size = max(subset_size)),
by = SNP]
N_TOP_SNPS <- 50
topN_SNPs <- vip_mean[order(-VIP_mean)][1:N_TOP_SNPS, SNP]
df_topNPLS <- results_vip[SNP %in% topN_SNPs]
df_topNPLS <- merge(df_topNPLS, vip_mean[, .(SNP, VIP_mean)], by = "SNP")
# Visualisation de la distribution du VIP pour les Top N SNP
ggplot(df_topNPLS, aes(x = reorder(SNP, VIP_mean), y = VIP)) +
geom_violin(trim = FALSE, aes(fill = SNP)) +
geom_boxplot(width = 0.1, outlier.size = 0.5) +
theme_bw() +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
) +
labs(
x = "SNP (Trié par VIP moyen)",
y = "Score VIP (par Fold et Itération)",
title = paste("Distribution du VIP pour les", N_TOP_SNPS, "SNP les plus importants"),
fill = "SNP"
) +
guides(fill = "none")
perf_by_size <- results_perf[, .(R2_mean = mean(R2_test, na.rm = TRUE),
R2_sd = sd(R2_test, na.rm = TRUE)),
by = subset_size]
print(perf_by_size)
# Visualisation par taille de subset
ggplot(results_perf, aes(x = factor(subset_size), y = R2_test, fill = factor(subset_size))) +
geom_boxplot() +
labs(title = expression("Performance R² par Taille de Sous-Ensemble de SNP"),
x = "Taille du Sous-Ensemble de SNP",
y = expression(R^2~"(Test Externe)"),
fill = "Taille") +
theme_minimal()
library(data.table)
snp_names <- colnames(X)
coords <- do.call(rbind, strsplit(colnames(geno), "_"))
chrom <- as.factor(coords[, 1])
pos <- as.numeric(coords[, 2])
# Création de la table de localisation
snp_localisation <- data.table(
SNP = colnames(geno),
Chromosome = chrom,
Position = pos
)
snp_localisation <- snp_localisation[!is.na(Position)]
# Calcul du VIP moyen par SNP
vip_stability <- results_vip[, .(VIP_mean = mean(VIP, na.rm = TRUE),
VIP_sd = sd(VIP, na.rm = TRUE),
N_Observations = .N),
by = SNP]
vip_loc <- merge(vip_stability, snp_localisation, by = "SNP", all.x = TRUE)
print(head(vip_loc[!is.na(Position)]))
VIP_THRESHOLD <- 3.0
# Filtrer les SNP sur le VIP moyen
important_snps <- vip_loc[VIP_mean > VIP_THRESHOLD]
cat(paste("Nombre de SNP conservés après le filtrage sur score VIP", ":", nrow(important_snps)))
important_snps
library(data.table)
library(ggplot2)
library(caret)
library(nnet)
library(pls)
library(FactoMineR)
library(qqman)
library(mixOmics)
data(Phenotype)
data(Genomic)
data("localisation")
pheno <- as.data.table(Phenotype)
loc_df<- as.data.table(localisation)
geno<- as.data.table(Genomic)
geno[, ID := rownames(Genomic)]
pheno[, ID := rownames(Phenotype)]
merged<- merge(pheno, loc_df[,list(Population,ID)], by = "ID")
merged<- merge(merged, geno, by = "ID")
df <- as.data.table(merged)
phenos <- names(df)[sapply(df, is.numeric)]
phenos <- setdiff(phenos, c("class_index","Lat","Lgn","ID"))
get_r2 <- function(var) {
form<- as.formula(paste(var, "~ Population"))
mod<- lm(form, data = df)
summary(mod)$r.squared
}
r2_values<- data.table(
phenotype = phenos,
r2= sapply(phenos, get_r2)
)
phenos
pheno <- as.data.table(Phenotype)
loc_df<- as.data.table(localisation)
geno<- as.data.table(Genomic)
geno[, ID := rownames(Genomic)]
pheno[, ID := rownames(Phenotype)]
merged<- merge(pheno, loc_df[,list(Population,ID)], by = "ID")
#merged<- merge(merged, geno, by = "ID")
phenos <- names(df)[sapply(df, is.numeric)]
phenos <- setdiff(phenos, c("class_index","Lat","Lgn","ID"))
phenos
df <- as.data.table(merged)
phenos <- names(df)[sapply(df, is.numeric)]
phenos <- setdiff(phenos, c("class_index","Lat","Lgn","ID"))
phenos
get_r2 <- function(var) {
form<- as.formula(paste(var, "~ Population"))
mod<- lm(form, data = df)
summary(mod)$r.squared
}
r2_values<- data.table(
phenotype = phenos,
r2= sapply(phenos, get_r2)
)
ggplot(r2_values, aes(x = reorder(phenotype, r2), y = r2)) +
geom_point(size = 3) +
geom_segment(aes(x = phenotype, xend = phenotype, y = 0, yend = r2)) +
coord_flip() +
ylab("R² lm(Phénotype ~ Population)") +
xlab("Caractère phénotypique") +
theme_minimal()
merged<- merge(merged, geno, by = "ID")
geno_mat <- as.matrix(geno)
coords <- do.call(rbind, strsplit(colnames(geno), "_"))
chrom <- as.factor(coords[,1])
pos <- as.numeric(coords[,2])
pca <- PCA(merged[,2:217022], quali.sup=21 ,quanti.sup=(2:20) )
library(pls)
library(caret)
library(data.table)
library(parallel)
library(doParallel)
library(data.table)
library(ggplot2)
library(nnet)
library(pls)
library(FactoMineR)
library(qqman)
library(mixOmics)
library(glmnet)
data(Phenotype)
data(Genomic)
data("localisation")
pheno <- as.data.table(Phenotype)
loc_df <- as.data.table(localisation)
geno <- as.data.table(Genomic)
geno[, ID := rownames(Genomic)]
pheno[, ID := rownames(Phenotype)]
merged <- merge(pheno, loc_df[, list(Population, ID)], by = "ID")
merged <- merge(merged, geno, by = "ID")
# Y : Phénotype, X : Matrice de SNP
y <- merged$CIRC2009
y <- as.numeric(y)
X <- as.matrix(merged[, 23:ncol(merged)])
set.seed(123)
K_outer <- 5
K_inner <- 5
outer_folds <- createFolds(y, k = K_outer, returnTrain = TRUE)
results <- data.frame(
outer_fold = integer(),
lambda_opt = numeric(),
R2 = numeric(),
RMSE = numeric()
)
SAVE_DIR <- "results_random_VIP_PLS"
# tous fichiers de performance
perf_files <- list.files(path = SAVE_DIR, pattern = "^perf_s5000.*\\.rds$", full.names = TRUE)
results_perf <- rbindlist(lapply(perf_files, readRDS))
# tous les fichiers VIP
vip_files <- list.files(path = SAVE_DIR, pattern = "^vip_s5000.*\\.rds$", full.names = TRUE)
results_vip <- rbindlist(lapply(vip_files, readRDS))
vip_mean <- results_vip[, .(VIP_mean = mean(VIP, na.rm = TRUE),
SNP_count = .N,
SNP_max_size = max(subset_size)),
by = SNP]
VIP_THRESHOLD <- 3.0
# Filtrer les SNP sur le VIP moyen
important_snps <- vip_mean[VIP_mean > VIP_THRESHOLD]
important_snps
X_sub <- X[,vip_mean$SNP]
set.seed(123)
K_outer <- 5
K_inner <- 5
outer_folds <- createFolds(y, k = K_outer, returnTrain = TRUE)
results <- data.frame(
outer_fold = integer(),
lambda_opt = numeric(),
R2 = numeric(),
RMSE = numeric()
)
for (f in 1:K_outer) {
print(f)
# Split externe
train_idx <- outer_folds[[f]]
test_idx  <- setdiff(seq_along(y), train_idx)
X_train <- X_sub[train_idx, ]
X_test  <- X_sub[test_idx, ]
y_train <- y[train_idx]
y_test  <- y[test_idx]
# CV interne pour le choix du lambda
cv_inner <- cv.glmnet(
x = X_train,
y = y_train,
alpha = 0,                # =0 pour pénalité Ridge ;)
nfolds = K_inner,
standardize = TRUE
)
lambda_opt <- cv_inner$lambda.min
# Modèle final
ridge_final <- glmnet(
x = X_train,
y = y_train,
alpha = 0,
lambda = lambda_opt,
standardize = TRUE
)
# Performances
y_pred <- as.vector(predict(ridge_final, newx = X_test))
R2_test <- cor(y_test, y_pred)^2
RMSE_test <- sqrt(mean((y_test - y_pred)^2))
results <- rbind(results, data.frame(
outer_fold = f,
lambda_opt = lambda_opt,
R2 = R2_test,
RMSE = RMSE_test
))
}
summary(results$R2)
mean(results$R2)
boxplot(results$R2)
for (f in 1:K_outer) {
print(f)
# Split externe
train_idx <- outer_folds[[f]]
test_idx  <- setdiff(seq_along(y), train_idx)
X_train <- X[train_idx, ]
X_test  <- X[test_idx, ]
y_train <- y[train_idx]
y_test  <- y[test_idx]
# CV interne pour le choix du lambda
cv_inner <- cv.glmnet(
x = X_train,
y = y_train,
alpha = 0,                # =0 pour pénalité Ridge ;)
nfolds = K_inner,
standardize = TRUE
)
lambda_opt <- cv_inner$lambda.min
# Modèle final
ridge_final <- glmnet(
x = X_train,
y = y_train,
alpha = 0,
lambda = lambda_opt,
standardize = TRUE
)
# Performances
y_pred <- as.vector(predict(ridge_final, newx = X_test))
R2_test <- cor(y_test, y_pred)^2
RMSE_test <- sqrt(mean((y_test - y_pred)^2))
results <- rbind(results, data.frame(
outer_fold = f,
lambda_opt = lambda_opt,
R2 = R2_test,
RMSE = RMSE_test
))
}
summary(results$R2)
mean(results$R2)
boxplot(results$R2)
X<- as.matrix(merged[,23:217022])
X2 <- X[, apply(X, 2, sd) != 0]
Y <- as.matrix(merged$CIRC2011)
result.spca.multi <- spca(X2, keepX = c(50, 30))
plotIndiv(result.spca.multi)
plotVar(result.spca.multi)
# extract the variables used to construct the first PC
selectVar(result.spca.multi, comp = 1)$name
# depict weight assigned to each of these variables
plotLoadings(result.spca.multi, method = 'mean', contrib = 'max')
pls.result <- mixOmics::pls(X, Y)
plotIndiv(pls.result)
plotIndiv(pls.result, group = merged$Population,
rep.space = 'XY-variate',
ellipse = TRUE,  # plot using the ellipses
legend = TRUE)
head(merged[,2:21])
Y <- as.matrix(merged[,2:21])
spls.result <- mixOmics::spls(X2, Y, ncomp=5, keepX = c(rep(1000,5)))
plotIndiv(spls.result, group = merged$Population,
rep.space = 'XY-variate',
ellipse = TRUE,  # plot using the ellipses
legend = TRUE)
# Identifier les coefficients non nuls
nonzero_idx <- loadX != 0
# use the mirna, mrna and protein expression levels as predictive datasets
# note that each dataset is measured across the same individuals (samples)
X1<- as.matrix(merged[,23:217022])
X1 <- X1[, apply(X1, 2, sd) != 0]
X2 <- as.matrix(merged[,2:21])
Y <- as.factor(merged$Population)
X <- list(geno = X1, pheno = X2)
result.diablo.tcga <- block.plsda(X, Y) # run the method
plotIndiv(result.diablo.tcga,
rep.space = 'XY-variate',
ellipse = TRUE,  # plot using the ellipses
legend = TRUE)
# set the number of features to use for the X datasets
list.keepX = list(geno = c(rep(10000,5)), pheno = c(rep(20,5)))
# run the method
result.sparse.diablo.tcga <-  block.splsda(X, Y, keepX = list.keepX, ncomp = 5)
plotLoadings(result.sparse.diablo.tcga, ncomp = 5)
plotIndiv(result.sparse.diablo.tcga,ellipse = TRUE,legend = TRUE)
plotVar(result.sparse.diablo.tcga) # plot the variables
plot(pca,choix="ind",habillage=21)
