ggplot(df_topN, aes(x = roerder(SNP), y = VIP, fill = SNP_count)) +
geom_violin(trim = FALSE) +
geom_boxplot(width = 0.1, outlier.size = 0.5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
theme_bw() +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
) +
labs(
x = "SNP",
y = "VIP",
title = "Distribution du VIP pour les n = 50 SNP les plus importants",
fill = "Nbr de selection du SNP"
)
# Violin plot avec couleur selon SNP_count
ggplot(df_topN, aes(x = reorder(SNP), y = VIP, fill = SNP_count)) +
geom_violin(trim = FALSE) +
geom_boxplot(width = 0.1, outlier.size = 0.5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
theme_bw() +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
) +
labs(
x = "SNP",
y = "VIP",
title = "Distribution du VIP pour les n = 50 SNP les plus importants",
fill = "Nbr de selection du SNP"
)
# Violin plot avec couleur selon SNP_count
ggplot(df_topN, aes(x = reorder(SNP,VIP), y = VIP, fill = SNP_count)) +
geom_violin(trim = FALSE) +
geom_boxplot(width = 0.1, outlier.size = 0.5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
theme_bw() +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
) +
labs(
x = "SNP",
y = "VIP",
title = "Distribution du VIP pour les n = 50 SNP les plus importants",
fill = "Nbr de selection du SNP"
)
library(data.table)
library(ggplot2)
# Calcul du VIP moyen par SNP
vip_mean<- results_vip[, .(VIP_mean = mean(VIP),SNP_count = .N), by = SNP]
# Sélection des 30 SNP ayant le VIP moyen le plus élevé
topN<- vip_mean[order(-VIP_mean)][0:50, SNP]
# Filtrage du jeu de données aux SNP sélectionnés
df_topN<- results_vip[SNP %in% topN]
df_topN
# Sélection des 30 SNP ayant le VIP moyen le plus élevé
topN<- vip_mean[order(-VIP_mean)][0:50, SNP]
# Filtrage du jeu de données aux SNP sélectionnés
df_topN<- results_vip[SNP %in% topN]
# Sélection des 30 SNP ayant le VIP moyen le plus élevé
topN<- vip_mean[order(-VIP_mean)][0:50, SNP]
# Filtrage du jeu de données aux SNP sélectionnés
df_topN<- results_vip[SNP %in% topN]
# Joindre le nombre d'apparitions à df_topN
df_topN <- merge(df_topN, vip_mean[, .(SNP, SNP_count)], by = "SNP")
df_topN$SNP_count <- df_topN$SNP_count/10
# Violin plot avec couleur selon SNP_count
ggplot(df_topN, aes(x = reorder(SNP,VIP), y = VIP, fill = SNP_count)) +
geom_violin(trim = FALSE) +
geom_boxplot(width = 0.1, outlier.size = 0.5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
theme_bw() +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
) +
labs(
x = "SNP",
y = "VIP",
title = "Distribution du VIP pour les n = 50 SNP les plus importants",
fill = "Nbr de selection du SNP"
)
# Violin plot avec couleur selon SNP_count
ggplot(df_topN, aes(x = reorder(SNP,VIP), y = VIP, fill = SNP_count)) +
geom_violin(trim = FALSE) +
geom_boxplot(width = 0.1, outlier.size = 0.5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
theme_bw() +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
) +
labs(
x = "SNP",
y = "VIP",
title = "Distribution du VIP pour les n = 50 SNP les plus importants",
fill = "Nbr de selection du SNP"
)
results_perf
vip_perf<- results_perf[, .(R2_test_mean = mean(R2_test)), by = iter]
vip_perf_fold<- results_perf[, .(R2_test_mean = mean(R2_test)), by = fold]
mean(vip_perf_fold$R2_test_mean)
vip_perf_fold
library(glmnet)
# Assurer que y est numérique et X est une matrice
y <- as.numeric(pheno$CIRC2009)
X <- as.matrix(geno)
# Ajustement du Lasso avec validation croisée pour choisir lambda
set.seed(123) # pour reproductibilité
cv_lasso <- cv.glmnet(X, y, alpha = 1, nfolds = 10)
# Afficher la meilleure valeur de lambda
best_lambda <- cv_lasso$lambda.min
print(best_lambda)
# Tracer l'erreur de validation croisée
plot(cv_lasso)
# Ajuster le modèle final avec lambda optimal
lasso_model <- glmnet(X, y, alpha = 1, lambda = best_lambda)
# Extraire les coefficients
coef(lasso_model)
coef(lasso_model)
# Convertir en data.frame pour manipuler facilement
coef_df <- data.frame(
SNP = rownames(lasso_coef),
Coefficient = as.numeric(lasso_coef)
)
lasso_coef <- coef(lasso_model)
# Convertir en data.frame pour manipuler facilement
coef_df <- data.frame(
SNP = rownames(lasso_coef),
Coefficient = as.numeric(lasso_coef)
)
# Garder seulement les coefficients différents de 0
coef_nonzero <- coef_df[coef_df$Coefficient != 0, ]
# Afficher le résultat
print(coef_nonzero)
topN<- coef_nonzero[order(-Coefficient)][0:50, SNP]
topN<- coef_nonzero[order(-coef_nonzero$Coefficient)][0:50, SNP]
topN<- coef_nonzero[order(-coef_nonzero$Coefficient)][1:50, SNP]
topN<- coef_nonzero[order(-coef_nonzero$Coefficient),][1:50, SNP]
topN<- coef_nonzero[order(-coef_nonzero$Coefficient),][1:50, coef_nonzero$SNP]
topN <- coef_nonzero[order(-coef_nonzero$Coefficient), ][1:50, "SNP"]
topN
# Conversion en data.table si ce n'est pas déjà le cas
coef_dt <- as.data.table(coef_nonzero)
# Calcul de la valeur absolue et tri décroissant
coef_dt[, abs_coef := abs(Coefficient)]
# Sélection du top N (par exemple N = 50)
N <- 50
topN_dt <- coef_dt[order(-abs_coef)][1:N, .(SNP, Coefficient)]
# Affichage
topN_dt
y_pred <- predict(lasso_model, newx = X)
# Calcul du R²
SSE <- sum((y - y_pred)^2)           # somme des carrés des erreurs
SST <- sum((y - mean(y))^2)         # somme totale des carrés
R2 <- 1 - SSE/SST
R2
library(glmnet)
# Assurer que y est numérique et X est une matrice
y <- as.numeric(pheno$CIRC2009)
X <- as.matrix(geno)
train_index <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[train_index, ]
X_test  <- X[-train_index, ]
y_train <- y[train_index]
y_test  <- y[-train_index]
# Ajustement du Lasso avec validation croisée pour choisir lambda
set.seed(123) # pour reproductibilité
cv_lasso <- cv.glmnet(X_train, y_train, alpha = 1, nfolds = 10)
# Afficher la meilleure valeur de lambda
best_lambda <- cv_lasso$lambda.min
print(best_lambda)
# Tracer l'erreur de validation croisée
plot(cv_lasso)
# Ajuster le modèle final avec lambda optimal
lasso_model <- glmnet(X, y, alpha = 1, lambda = best_lambda)
# Extraire les coefficients
coef(lasso_model)
y_pred <- predict(lasso_model, newx = X_test)
# Calcul du R²
SSE <- sum((y_test - y_pred)^2)           # somme des carrés des erreurs
SST <- sum((y_test - mean(y))^2)         # somme totale des carrés
R2 <- 1 - SSE/SST
R2
lasso_coef <- coef(lasso_model)
# Convertir en data.frame pour manipuler facilement
coef_df <- data.frame(
SNP = rownames(lasso_coef),
Coefficient = as.numeric(lasso_coef)
)
# Garder seulement les coefficients différents de 0
coef_nonzero <- coef_df[coef_df$Coefficient != 0, ]
# Afficher le résultat
print(coef_nonzero)
topN <- coef_nonzero[order(-coef_nonzero$Coefficient), ][1:50, "SNP"]
# Conversion en data.table si ce n'est pas déjà le cas
coef_dt <- as.data.table(coef_nonzero)
# Calcul de la valeur absolue et tri décroissant
coef_dt[, abs_coef := abs(Coefficient)]
# Sélection du top N (par exemple N = 50)
N <- 50
topN_dt <- coef_dt[order(-abs_coef)][1:N, .(SNP, Coefficient)]
# Affichage
topN_dt
library(glmnet)
# Assurer que y est numérique et X est une matrice
y <- as.numeric(pheno$CIRC2009)
X <- as.matrix(geno)
train_index <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[train_index, ]
X_test  <- X[-train_index, ]
y_train <- y[train_index]
y_test  <- y[-train_index]
# Ajustement du Lasso avec validation croisée pour choisir lambda
set.seed(123) # pour reproductibilité
cv_lasso <- cv.glmnet(X_train, y_train, alpha = 1, nfolds = 10)
# Afficher la meilleure valeur de lambda
best_lambda <- cv_lasso$lambda.min
print(best_lambda)
# Tracer l'erreur de validation croisée
plot(cv_lasso)
# Ajuster le modèle final avec lambda optimal
lasso_model <- glmnet(X_train, y_train, alpha = 1, lambda = best_lambda)
# Extraire les coefficients
coef(lasso_model)
y_pred <- predict(lasso_model, newx = X_test)
# Calcul du R²
SSE <- sum((y_test - y_pred)^2)           # somme des carrés des erreurs
SST <- sum((y_test - mean(y))^2)         # somme totale des carrés
R2 <- 1 - SSE/SST
R2
lasso_coef <- coef(lasso_model)
# Convertir en data.frame pour manipuler facilement
coef_df <- data.frame(
SNP = rownames(lasso_coef),
Coefficient = as.numeric(lasso_coef)
)
# Garder seulement les coefficients différents de 0
coef_nonzero <- coef_df[coef_df$Coefficient != 0, ]
# Afficher le résultat
print(coef_nonzero)
library(glmnet)
# Assurer que y est numérique et X est une matrice
y <- as.numeric(pheno$CIRC2009)
X <- as.matrix(geno)
train_index <- createDataPartition(y, p = 0.9, list = FALSE)
X_train <- X[train_index, ]
X_test  <- X[-train_index, ]
y_train <- y[train_index]
y_test  <- y[-train_index]
# Ajustement du Lasso avec validation croisée pour choisir lambda
set.seed(123) # pour reproductibilité
cv_lasso <- cv.glmnet(X_train, y_train, alpha = 1, nfolds = 10)
# Afficher la meilleure valeur de lambda
best_lambda <- cv_lasso$lambda.min
print(best_lambda)
# Tracer l'erreur de validation croisée
plot(cv_lasso)
# Ajuster le modèle final avec lambda optimal
lasso_model <- glmnet(X_train, y_train, alpha = 1, lambda = best_lambda)
# Extraire les coefficients
coef(lasso_model)
y_pred <- predict(lasso_model, newx = X_test)
# Calcul du R²
SSE <- sum((y_test - y_pred)^2)           # somme des carrés des erreurs
SST <- sum((y_test - mean(y))^2)         # somme totale des carrés
R2 <- 1 - SSE/SST
R2
coef_df <- data.frame(
SNP = rownames(coef(lasso_model)),
Coefficient = as.numeric(coef(lasso_model))
)
coef_nonzero <- coef_df[coef_df$Coefficient != 0, ]
coef_nonzero_dt <- as.data.table(coef_nonzero)
# Top N SNP par valeur absolue des coefficients
N <- 50
coef_nonzero_dt[, abs_coef := abs(Coefficient)]
topN_dt <- coef_nonzero_dt[order(-abs_coef)][1:N, .(SNP, Coefficient)]
topN_dt
# Sélection des 30 SNP ayant le VIP moyen le plus élevé
topN<- vip_mean[order(-VIP_mean)][0:50, SNP]
df_topNPLS<- results_vip[SNP %in% topN]
df_topNPLS <- merge(df_topNPLS, vip_mean[, .(SNP, SNP_count)], by = "SNP")
df_topNPLS$SNP_count <- df_topNPLS$SNP_count/10
ggplot(df_topNPLS, aes(x = reorder(SNP,VIP), y = VIP, fill = SNP_count)) +
geom_violin(trim = FALSE) +
geom_boxplot(width = 0.1, outlier.size = 0.5) +
scale_fill_gradient(low = "lightblue", high = "darkblue") +
theme_bw() +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
) +
labs(
x = "SNP",
y = "VIP",
title = "Distribution du VIP pour les n = 50 SNP les plus importants",
fill = "Nbr de selection du SNP"
)
hist(vip_mean$VIP_mean, breaks = seq(min(vip_mean$VIP_mean), max(vip_mean$VIP_mean), length.out = 50),
main = "Distribution des scores VIP moyens",
xlab = "scores VIP moyens", col = "lightblue", border = "white")
# Trouver les SNP présents dans les deux listes
common_snps <- intersect(df_topNPLS, topN_Lasso)
coef_df <- data.frame(
SNP = rownames(coef(lasso_model)),
Coefficient = as.numeric(coef(lasso_model))
)
coef_nonzero <- coef_df[coef_df$Coefficient != 0, ]
coef_nonzero_dt <- as.data.table(coef_nonzero)
# Top N SNP par valeur absolue des coefficients
N <- 50
coef_nonzero_dt[, abs_coef := abs(Coefficient)]
topN_Lasso <- coef_nonzero_dt[order(-abs_coef)][1:N, .(SNP, Coefficient)]
topN_Lasso
# Trouver les SNP présents dans les deux listes
common_snps <- intersect(df_topNPLS, topN_Lasso)
# Afficher les SNP communs
common_snps
# Trouver les SNP présents dans les deux listes
common_snps <- intersect(df_topNPLS, coef_nonzero)
# Afficher les SNP communs
common_snps
coef_nonzero
coef_nonzero$SNP
# Trouver les SNP présents dans les deux listes
common_snps <- intersect(df_topNPLS, coef_nonzero$SNP)
# Afficher les SNP communs
common_snps
# Sélection des 30 SNP ayant le VIP moyen le plus élevé
topN<- vip_mean[order(-VIP_mean)][0:5000, SNP]
df_topNPLS<- results_vip[SNP %in% topN]
df_topNPLS <- merge(df_topNPLS, vip_mean[, .(SNP, SNP_count)], by = "SNP")
df_topNPLS$SNP_count <- df_topNPLS$SNP_count/10
# Trouver les SNP présents dans les deux listes
common_snps <- intersect(df_topNPLS, coef_nonzero$SNP)
# Afficher les SNP communs
common_snps
df_topNPLS
# Trouver les SNP présents dans les deux listes
common_snps <- intersect(df_topNPLS$SNP, coef_nonzero$SNP)
# Afficher les SNP communs
common_snps
common_snps <- intersect(df_topNPLS$SNP, coef_nonzero$SNP)
# SNP communs
common_snps
length(common_snps)
ggplot(results_perf[1:30,], aes(x = factor(iter), y = R2_test)) +
geom_violin(fill = "skyblue", color = "black") +
labs(x = "Itération", y = expression(R^2), title = "Variabilité des R² par itération") +
theme_minimal()
ggplot(results_perf[1:110,], aes(x = factor(iter), y = R2_test)) +
geom_violin(fill = "skyblue", color = "black") +
labs(x = "Itération", y = expression(R^2), title = "Variabilité des R² par itération") +
theme_minimal()
ggplot(results_perf[1:1000,], aes(x = factor(iter), y = R2_test)) +
geom_violin(fill = "skyblue", color = "black") +
labs(x = "Itération", y = expression(R^2), title = "Variabilité des R² par itération") +
theme_minimal()
ggplot(results_perf[1:1000,], aes(x = factor(iter), y = R2_test)) +
geom_violin(fill = "skyblue", color = "black") +
labs(x = "Itération", y = expression(R^2), title = "R² 10-outer-fold ") +
theme_minimal()
set.seed(123)
# Paramètres
n_iter <- 400
subset_size <- 10000     # nombre de SNP aléatoires par itération
ncomp_candidates <- 1:5  # candidats pour ncomp
nfold_outer <- 5
nfold_inner <- 10
# --- Données ---
y <- pheno$CIRC2009
y <- as.numeric(y)
X <- as.matrix(geno)
# Fonction pour calculer les VIP
calc_vip <- function(pls_model) {
W <- pls_model$loading.weights
SSY <- colSums(pls_model$Yscores^2)
p <- nrow(W)
A <- ncol(W)
vip <- numeric(p)
for (j in 1:p) {
vip[j] <- sqrt(p * sum(SSY * (W[j, ]^2)) / sum(SSY))
}
names(vip) <- rownames(W)
return(vip)
}
# Préparer cluster parallèle
n_cores <- parallel::detectCores() - 2
cl <- makeCluster(n_cores)
registerDoParallel(cl)
# --- Pipeline principal ---
out <- foreach(i = 1:n_iter, .packages = c("pls","caret","data.table")) %dopar% {
# 1) Tirage aléatoire SNP
snp_cols <- sample(colnames(X), subset_size)
X_sub <- X[, snp_cols]
# 2) Split en folds externes
folds <- createFolds(y, k = nfold_outer, list = TRUE)
# Tables locales
perf_list <- list()
vip_list  <- list()
for(f in seq_len(nfold_outer)) {
test_idx  <- folds[[f]]
train_idx <- setdiff(seq_len(nrow(X_sub)), test_idx)
X_train <- X_sub[train_idx, ]
y_train <- y[train_idx]
X_test  <- X_sub[test_idx, ]
y_test  <- y[test_idx]
# 3) Sélection ncomp via CV interne
pls_cv <- plsr(y_train ~ X_train,
ncomp = max(ncomp_candidates),
validation = "CV",
segments = nfold_inner)
best_ncomp <- selectNcomp(pls_cv, method = "onesigma") + 1
# Ajustement final
pls_model <- plsr(y_train ~ X_train, ncomp = best_ncomp)
# 4) Performance test
y_pred <- predict(pls_model, newdata = X_test, ncomp = best_ncomp)
R2_test  <- cor(y_test, y_pred)^2
RMSE_test <- sqrt(mean((y_test - y_pred)^2))
# 5) VIP
vip <- calc_vip(pls_model)
# 6) Stockage séparé
# performances fold-level
perf_list[[f]] <- data.table(
iter = i,
fold = f,
ncomp = best_ncomp,
R2_test = R2_test,
RMSE_test = RMSE_test
)
# VIP SNP-level
vip_list[[f]] <- data.table(
SNP = names(vip),
VIP = as.numeric(vip),
iter = i,
fold = f
)
}
list(
perf = rbindlist(perf_list),
vip  = rbindlist(vip_list)
)
}
stopCluster(cl)
# Reconstruction finale dans l'ordre
results_perf <- rbindlist(lapply(out, `[[`, "perf"))
results_vip  <- rbindlist(lapply(out, `[[`, "vip"))
y <- as.numeric(pheno$CIRC2009)
X <- as.matrix(geno)
# Split externe train/test
set.seed(123)
train_index <- createDataPartition(y, p = 0.9, list = FALSE)
X_train <- X[train_index, ]
X_test  <- X[-train_index, ]
y_train <- y[train_index]
y_test  <- y[-train_index]
# Split interne du train en D1 et D2 : 50/50
set.seed(123)
idx_D1 <- createDataPartition(y_train, p = 0.5, list = FALSE)
X_D1 <- X_train[idx_D1, ]
X_D2 <- X_train[-idx_D1, ]
y_D1 <- y_train[idx_D1]
y_D2 <- y_train[-idx_D1]
set.seed(123)
cv_enet <- cv.glmnet(
X_D1, y_D1,
alpha = 0.5,               # Elastic Net
nfolds = 10,
standardize = TRUE
)
lambda_hat <- cv_enet$lambda.min
# Ajustement final Elastic Net sur D1
enet_model <- glmnet(X_D1, y_D1, alpha = 0.5, lambda = lambda_hat)
# En variables sélectionnées : support
coefs <- coef(enet_model)
selected <- which(coefs[-1] != 0)          # indices des SNP sélectionnés
S_hat <- selected
cat("Nombre de variables sélectionnées (screening):", length(S_hat), "\n")
# Poids dérivés des coefficients Elastic Net
beta_hat <- as.numeric(coefs[-1])
weights <- abs(beta_hat)
weights <- weights[S_hat]
weights <- weights / max(weights)          # normalisation
X_D2_sel <- X_D2[, S_hat, drop = FALSE]
# Pondération Ridge : mettre plus de pénalité sur les petites β_EN
ridge_penalty <- 1 / (weights + 1e-6)
set.seed(123)
cv_ridge <- cv.glmnet(
X_D2_sel, y_D2,
alpha = 0,                     # alpha = 0 → Ridge
nfolds = 10,
penalty.factor = ridge_penalty
)
lambda_ridge <- cv_ridge$lambda.min
# Ajustement final sur D2
ridge_model <- glmnet(
X_D2_sel, y_D2,
alpha = 0,
lambda = lambda_ridge,
penalty.factor = ridge_penalty
)
# Coefficients ridge finaux (sur D2)
beta_clean <- coef(ridge_model)
X_train_sel <- X_train[, S_hat, drop = FALSE]
ridge_final <- glmnet(
X_train_sel, y_train,
alpha = 0,
lambda = lambda_ridge,
penalty.factor = ridge_penalty
)
# Prédictions sur le test externe
X_test_sel <- X_test[, S_hat, drop = FALSE]
y_pred <- predict(ridge_final, newx = X_test_sel)
# R² externe
R2_test <- 1 - sum((y_test - y_pred)^2) / sum((y_test - mean(y_test))^2)
cat("R2 externe :", R2_test, "\n")
