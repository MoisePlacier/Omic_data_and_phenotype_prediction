% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{setspace}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
  \setmainfont[]{Times New Roman}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=2cm]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\usepackage[colorlinks=true, linkcolor=blue]{hyperref}
\usepackage[acronym]{glossaries}
\makeglossaries
\DeclareUnicodeCharacter{221E}{$\infty$}
\DeclareUnicodeCharacter{2192}{$\to$}
\DeclareUnicodeCharacter{00B0}{$^\circ$}
\DeclareUnicodeCharacter{03B1}{$\alpha$}
\DeclareUnicodeCharacter{03B2}{$\beta$}
\usepackage[backend=biber, style=authoryear, citestyle=authoryear, url=true, urldate=long]{biblatex}
\setlength{\bibitemsep}{1em}
\addbibresource{bibliographie_peuplier.bib}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table des matières}
\else
  \newcommand\contentsname{Table des matières}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{Liste des Figures}
\else
  \newcommand\listfigurename{Liste des Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{Liste des Tables}
\else
  \newcommand\listtablename{Liste des Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{Liste des Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
\babelprovide[main,import]{french}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Comparaison d'approches linéaires et non-linéaires pour le scoring de SNPs et la prédiction de caractères complexes chez Populus nigra.},
  pdfauthor={Placier Moïse \& Fabrice Traore},
  pdflang={fr},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Comparaison d'approches linéaires et non-linéaires pour le
scoring de SNPs et la prédiction de caractères complexes chez Populus
nigra.}
\author{Placier Moïse \& Fabrice Traore}
\date{2026-01-19}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[frame hidden, enhanced, interior hidden, boxrule=0pt, borderline west={3pt}{0pt}{shadecolor}, breakable, sharp corners]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table des Matières}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{3}
\tableofcontents
}
\setstretch{1.2}
\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Notre travail a été réalisé en partenariat avec l'unité
\href{https://biofora.val-de-loire.hub.inrae.fr/}{BioForA} (Biologie
intégrée pour la valorisation de la diversité des arbres et de la forêt)
du centre INRAE Val de Loire. Il prend place dans la continuité directe
des travaux de thèse menés par Alexandre Duplan, sous l'encadrement de
Harold Duruflé et Leopoldo Sanchez-Rodriguez. Le projet vise à
comprendre les mécanismes d'adaptation des arbres forestiers,
spécifiquement le peuplier noir (Populus nigra), face aux changements
environnementaux.

Pour ce faire, nous exploitons des données multi-omiques (génomique,
épigénomique, transcriptomique) issues des projets
\href{https://anr.fr/Projet-ANR-13-JSV6-0001}{ANR SYBIOPOP} et
\href{https://epitree-project.hub.inrae.fr/}{EPITREE}. L'objectif de
notre travail est de construire des modèles capables de prédire des
traits phénotypiques complexes (croissance, phénologie, résistance aux
maladies) à partir des données génomiques.

\hypertarget{lhuxe9ritage-muxe9thodologique}{%
\subsection{L'héritage
méthodologique}\label{lhuxe9ritage-muxe9thodologique}}

Les travaux conduits précédemment au sein de l'unité ont permis la
constitution et la curation d'un jeu de données de référence regroupant
199 individus de peupliers noirs (Populus nigra). Sur cette base, les
recherches d'Alexandre Duplan ont exploré diverses stratégies de
modélisation pour la prédiction de caractères complexes à partir de
données multi-omiques. Sa méthodologie repose sur une intégration
précoce (early integration) consistant en la concaténation des
différentes couches omiques, traitées ensuite par des algorithmes de
régression Ridge ou de Random Forest. Ce choix technique permet
d'appréhender le système biologique de manière unifiée, en traitant
l'ensemble des l'information sur le même plan.

Néanmoins, cette approche augmente considérablement la dimensionnalité
du jeu de données, soulevant plusieurs défis méthodologiques.
Premièrement, l'hétérogénéité du nombre de variables entre les couches
omiques induit un déséquilibre structurel : les couches les plus denses
(nottament les 3 contextes épigénétiques) surreprésentent l'information,
biaisant ainsi la contribution relative de chaque niveau omique au sein
du modèle. Deuxièmement, l'augmentation du nombre de variables
complexifie l'interprétation des résultats. La présence de variables non
informatives, sans lien biologique avec le caractère étudié, dilue le
signal causal. Cela rend difficile l'identification précise des locus
d'intérêt ainsi que la quantification de la part de variance expliquée
par ces derniers.

Pour pallier ces limites, Alexandre Duplan a développé un filtre de
sélection de variables visant à ne conserver que les marqueurs les plus
informatifs de chaque couche. Dans cette optique de réduction de
dimension, il a mis en œuvre un modèle mixte multi-locus (MLMM), qui est
une approche de GWAS (Genome-Wide Association Study), afin d'évaluer
l'association statistique de chaque SNP avec les phénotypes. En
sélectionnant les marqueurs présentant les p-values les plus
significatives (inférieures à un seuil défini), il a pu isoler un
ensemble de 31 754 SNPs associés de manière significative aux différents
caractères, réduisant ainsi la dimensionalité du jeu de donné génomique
avant l'étape d'intégration.

Cette stratégie de filtrage à eu un effet variable sur les performances
de prédictions des différents phénotypes : tantôt positif, tantôt
négatif. Alexandre Duplan suggère que ce filtre à pu éliminer du bruit,
mais également des variables explicatives réelles, ce qui s'est traduit
parfois par une dégradation des performances du modèle. Les analyses
comparatives ont également révélé un résultat contre-intuitif; la
performance prédictive obtenue à partir d'un sous-ensemble de marqueurs
génomique de même taille mais sélectionnés aléatoirement s'avère
équivalente à celle obtenue via une sélection ciblée par MLMM/GWAS.

\hypertarget{objectifs-de-luxe9tude-et-hypothuxe8ses-de-travail}{%
\subsection{Objectifs de l'étude et hypothèses de
travail}\label{objectifs-de-luxe9tude-et-hypothuxe8ses-de-travail}}

/ ici. je souhaite modifier l'approche point de départ = 1 constat :
performances prédictives : Selection MLMM (initialement employé pour
réduire les faux positifs et améliorer l'explicabilité des résultats) =
selection aléatoire + Notre Objectif : améliorer les performances
prédictives et améliorer l'explicabilité des modèles.

Ce que l'on sait : population très structuré, la biblio dit : la
précision d'un modèle génomique est une résultante composite de :
L'apparentement global (Structure/Kinship). Le déséquilibre de liaison
(LD) avec les marqueurs. Les effets spécifiques des QTLs (Loci de Traits
Quantitatifs).

=\textgreater{} Il y a une tension direct entre les l'objectif améliorer
performance de prédictions et améliorer l'explicabilité des modèles(=
identifier les variants causaux spécifiques des caractères).

Les analyses antérieures présentaient une incohérence structurelle dans
le traitement de l'information : la sélection des SNPs était effectuée
via un modèle MLMM (corrigé pour la structure), tandis que l'évaluation
des performances de prédiction s'appuyait sur le phénotype brut. il est
impossible de déterminer si la performance prédictive observée (\(R^2\))
provient de la pertinence biologique des marqueurs sélectionnés ou d'un
simple effet de rappel de la structure de population.

Hypothèses sur les observations précédentes

Les bonnes performances obtenues avec de larges sous-ensembles
aléatoires de SNPs s'expliqueraient principalement par la capacité de
ces ensembles à capturer la structure de population et la parenté, qui
constituent un proxy puissant du phénotype mesuré. Cette information,
bien que prédictive, n'est pas directement informative sur les
mécanismes biologiques sous-jacents.

Le plafonnement du \(R^2\) observé dans les analyses précédentes suggère
que la sélection initiale de SNPs n'incluait pas l'ensemble des variants
contribuant effectivement au phénotype, soit en raison d'un nombre de
SNPs sélectionnés insuffisant, soit en raison de limites méthodologiques
dans l'identification de leur importance.

Nous faison donc le choix méthodologique de travailler sur les résidus
déflatés des effets de structures car : 1) moins de faux négatifs sur
les variants causaux identifiés Price et al.~(2006) et Yu et al.~(2006).
2) L'utilisation des variants causaux pour la prédictions rends plus
robuste car Selon Spiliopoulou et al.~(2015), dans un contexte de
prédiction « across-cohort » (entre cohortes différentes ou populations
non corrélées), les modèles « sparses » (parcimonieux) ciblant
spécifiquement les variants causaux ont une meilleure capacité de
généralisation.

Hypothèses :

Hypothèses de travail

Chaque phénotype est supposé être déterminé par un nombre variable mais
limité de régions fonctionnelles, reflétant la complexité biologique du
trait.

Une sélection de variables basée sur un protocole de Random Forest avec
subsampling aléatoire et agrégation des scores d'importance permettrait
d'identifier ces SNPs en capturant des effets non additifs et des
interactions locales échappant aux modèles linéaires. Cette sélection
devrait enrichir l'ensemble de SNPs en variants biologiquement
pertinents, indépendamment de la structure de population. (Genome-wide
prediction with non-additive models (González-Recio \& Forni, 2011))

L'utilisation de cet ensemble restreint de SNPs dans des modèles de
prédiction finale, qu'il s'agisse d'un modèle ridge ou d'un Random
Forest, devrait permettre d'améliorer ou de maintenir les performances
prédictives tout en augmentant la robustesse et l'interprétabilité
biologique des résultats. Les différences de performances entre le ridge
et le RF final fourniront en outre une indication sur le degré de
non-linéarité et d'interactions résiduelles dans l'architecture
génétique du trait.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Contexte et Héritage Méthodologique
\end{enumerate}

Les travaux antérieurs de l'unité ont permis la constitution d'un jeu de
données de référence sur 199 individus de peuplier noir (Populus nigra).
Sur cette base, les premières stratégies de prédiction génomique (A.
Duplan) ont reposé sur une intégration précoce (early integration) des
données multi-omiques, traitées par Ridge Regression ou Random Forest.
Bien que cette approche unifiée permette de saisir le système biologique
dans son ensemble, elle se heurte à une dimensionnalité excessive qui
dilue le signal causal dans un bruit de fond massif.

Pour tenter de réduire cette dimension, une présélection de variables
par modèle mixte (MLMM/GWAS) a été testée. Cependant, les résultats ont
révélé un ``paradoxe de la sélection'' : la performance prédictive
obtenue via une sélection ciblée par GWAS s'avère équivalente à celle
d'un sous-ensemble aléatoire de SNPs de même taille. Ce résultat suggère
que les modèles actuels sont saturés par un signal global non spécifique
au phénotype étudié.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  La Tension Méthodologique des travaux précédents
\end{enumerate}

Les analyses antérieures présentaient une incohérence structurelle dans
le traitement de l'information : la sélection des SNPs était effectuée
via un modèle MLMM (corrigé pour la structure), tandis que l'évaluation
des performances de prédiction s'appuyait sur le phénotype brut.

il est impossible de déterminer si la performance prédictive observée
(\(R^2\)) provient de la pertinence biologique des marqueurs
sélectionnés ou d'un simple effet de rappel de la structure de
population. En effet, comme le soulignent Habier et al.~(2007) et
Spiliopoulou et al.~(2017), la précision d'un modèle génomique est une
résultante composite de :

L'apparentement global (Structure/Kinship). Le déséquilibre de liaison
(LD) avec les marqueurs. Les effets spécifiques des QTLs (Loci de Traits
Quantitatifs).

En prédisant sur le phénotype brut, la composante ``Apparentement''
sature le signal, rendant invisible la contribution réelle des QTLs et
expliquant pourquoi une sélection aléatoire (qui capture aussi
l'apparentement) performe aussi bien qu'une sélection ciblée.

Dans une population fortement structurée comme celle du peuplier noir,
un grand nombre de SNPs aléatoires capture efficacement la composante
``Apparentement'', agissant comme un proxy du phénotype sans pour autant
identifier les mécanismes biologiques (Daetwyler et al., 2013). Cette
prédiction par ``proximité génétique'' présente une limite majeure :
elle masque le signal des régions fonctionnelles et empêche
l'interprétabilité biologique. Pour dépasser ce plafond et isoler les
variants causaux, il est impératif de neutraliser les effets de
confusion liés à la démographie (Astle \& Balding, 2010). Conformément
aux principes établis par Price et al.~(2006) et Yu et al.~(2006), la
correction de la structure (via PCA ou modèles mixtes Q+K) est un
prérequis pour distinguer les associations fortuites des véritables
signaux biologiques.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Objectifs de l'étude
\end{enumerate}

L'objectif central de cette étude est de passer d'une prédiction fondée
sur la structure de population à une prédiction fondée sur
l'architecture génétique du trait.Nous cherchons à identifier un
ensemble restreint et pertinent (parsimonieux) de SNPs, localisés dans
des régions fonctionnelles impliquées dans le déterminisme du trait,
puis à exploiter cet ensemble pour la prédiction finale. Cette démarche
vise deux buts conjoints :

Améliorer ou maintenir la précision prédictive (\(R^2\)) en maximisant
la composante liée aux effets de QTL spécifiques (LD-based prediction).

Garantir l'interprétabilité biologique en s'assurant que les marqueurs
sélectionnés pointent vers des régions régulatrices ou codantes
causales, et non vers des artefacts de structure.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Hypothèses de travailPour répondre à ces objectifs, nous formulons les
  hypothèses suivantes :
\end{enumerate}

Hypothèse 1 : Spécificité fonctionnelle et architecture du trait

Chaque phénotype est déterminé par un nombre variable mais limité de
régions fonctionnelles (architecture oligogénique ou polygénique
modérée). L'identification précise de ces zones, une fois le signal de
structure déflaté, permet de capturer la variabilité phénotypique
réelle, là où les approches globales sont saturées par le bruit de fond.

Hypothèse 1bis : Influence de la colinéarité ``Adaptation-Structure''
Nous supposons que l'impact de la déflation sur les performances de
prédiction dépendra du degré de stratification adaptive du trait :

\begin{itemize}
\item
  Pour les traits liés à l'adaptation locale (ex: phénologie), la
  déflation devrait réduire le \(R^2\) car le signal biologique est
  intrinsèquement colinéaire à la structure de population (Berg \& Coop,
  2014).
\item
  Pour les traits moins structurés, la déflation devrait au contraire
  augmenter les performances en supprimant le bruit de fond structural,
  permettant ainsi aux modèles (notamment Random Forest) de se focaliser
  sur le signal fonctionnel pur.
\end{itemize}

Hypothèse 2 : Supériorité de la sélection non-linéaire (Random Forest)

Les modèles linéaires classiques (type MLMM) échouent à capturer une
part de l'héritabilité due aux interactions complexes (épistasie). Une
sélection de variables basée sur un protocole de Random Forest, via
l'agrégation des scores d'importance, permet d'identifier des SNPs
impliqués dans des effets non-additifs échappant aux GWAS standards
(González-Recio \& Forni, 2011).

Nous postulons que l'utilisation de la Random Forest (RF) permet
d'identifier des interactions complexes (gène x gène) qui échappent aux
modèles linéaires de type MLMM. Là où le MLMM capture la contribution
additive infinitésimale, le RF détecterait des dépendances non linéaires
et des effets épistatiques. Nous supposons donc que ces deux méthodes ne
voient pas le même signal génétique et que les deux méthodes ne sont pas
redondantes mais complémentaires.

Nous émettons l'hypothèse que le scoring par RF aboutit à une sélection
de SNPs plus restreinte mais plus dense en information. En isolant les
combinaisons de variants les plus prédictives, la RF permettrait de
s'affranchir des signaux redondants liés au Déséquilibre de Liaison (LD)
et à la structure de population. Le scoring par RF aboutirait à une
sélection de SNPs qui seraient plus spécifique des processus biologiques
du caractère étudié et situés sur des locus fonctionnels.

Si cette hypothèse se confirme, l'intérêt majeur réside dans un gain
direct en explicabilité. En réduisant le nombre de SNPs candidats à une
liste de locus hautement spécifiques au caractère étudié, nous
facilitons l'interprétation biologique grâce à l'identification de gènes
candidats ou des voies métaboliques spécifiques.

Hypothèse 3 : Le gain par la parsimonie

L'utilisation d'un subset de SNPs ``nettoyé'' de la structure et enrichi
en signal fonctionnel permettra, dans les modèles de prédiction finale
(Ridge ou RF), d'atteindre une robustesse supérieure. Si les
performances du modèle Random Forest final dépassent celles du modèle
Ridge sur ce subset sélectionné, cela confirmera l'existence d'une
architecture génétique complexe (non-linéaire) que nous aurons réussi à
capturer.

\hypertarget{ruxe9sultats}{%
\subsection{Résultats :}\label{ruxe9sultats}}

Résultats :

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Pour les les traits très corréllés à la strucuture de la population
  =\textgreater{} R\^{}2 diminue sur le phénotype déflaté : Pour les
  selections aléatoires de subset de SNP =\textgreater{} le R\^{}2 tombe
  à presque 0 !
\end{enumerate}

On vérifie l'hypothèses : A population genetic signal of polygenic
adaptation (Berg \& Coop, 2014) / Convergent adaptation of human lactase
persistence (Tishkoff et al., 2007) / Pour les traits liés à la
structure, la déflation devrait réduire le \(R^2\) car le signal
biologique est intrinsèquement colinéaire à la structure de population
(Berg \& Coop, 2014)

Par contre cool car les traits très peux corrélés a la pop : R\^{}2
augmente considérablement !!! vérifie : - Pour les traits moins
structurés, la déflation devrait au contraire augmenter les performances
en supprimant le bruit de fond structural, permettant ainsi aux modèles
de se focaliser sur le signal fonctionnel pur.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Egalement, Lorsque l'on compare les performances de prédictions sur le
  phénotype Brut ou déflaté pour un même caractère : Lorsque le
  caractère est peu lié a la population, le R\^{}2 reste sensiblment le
  même Lorsque le caractère est très lié a la pop, Le R\^{}2 sur le
  phéno Brut s'éffondre (pas à 0 mais -40\% quoi)
\end{enumerate}

confirme : A population genetic signal of polygenic adaptation (Berg \&
Coop, 2014) / Convergent adaptation of human lactase persistence
(Tishkoff et al., 2007). Les bonnes performances obtenues avec de larges
sous-ensembles aléatoires de SNPs s'expliqueraient principalement par la
capacité de ces ensembles à capturer la structure de population et la
parenté, qui constituent un proxy puissant du phénotype mesuré.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Pour certains phénotypes très peu corréllés à la pop (anle insertion
  des branches), on réussit a identifier un top 20-30 SNP qui a des
  performances de prédictions énormes !
\end{enumerate}

Par contre, lorsque le trait est complex il faut un nombre bcp plus
importants de SNP : entre 1000 et 5000 SNP !

Beaux résultats !!!!

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Analyse divergence du signal capturé par les différentes méthodes pour
  un phénotype :
\end{enumerate}

Résultats 1) : Le RF qui fait la selections de SNP sur le phéno pas
déflaté =\textgreater{} performance prédictives nulles R\^{}2 diminue
sur le phénotype déflaté. Il capture également des signaux
transphénotypes (\% overlap top 100 SNP pour différents phénotype trés
elevé) non spécifiques des phénotypes : surement très liés a la
population !

résultats 2) : De manière général, une selection par RF ou par LMM
aboutit relativement aux même R\^{}2 ! Etonnant car : résultats 3) La
selection de SNP par RF sur phéno déflaté ne capture pas dutoût le même
signal que les méthodes linéaires !\\
overlap du top 100 SNP pour un même phéno environ de 30\% + Extraction
du Top 5000 SNPs pour chaque méthode (GWAS et RF) Calcul du Déséquilibre
de Liaison (LD) entre tous les SNPs de cet ensemble

=\textgreater{} Le coût de transport d\_ij n'est plus une distance
physique, mais une distance de corrélation Une partie de l'importance
identifiée par la Random Forest se situe sur des blocs d'haplotypes
distincts de ceux identifiés par le GWAS.

=\textgreater{} Un score de 0.42 signifie qu'en moyenne, il faut
déplacer 40\% de la ``masse d'importance'' vers des haplotypes
totalement non corrélés pour faire correspondre les deux méthodes.

Ouverture possible : il serait génial d'investiguer par Gène Onthologie
ou autre outils biostats : les QTL disjoints identifiés par chaque
méthodes pour caractériser ce signal.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  identification d'un Traits adaptatifs et effets masqués par la
  correction (snp du chromosome 13)
\end{enumerate}

effet transphénotypique (top SNP pour plusieurs caractère complexe)
capturé par la méthode de RF sur phénotype brut. Fréquence allèlique
montr très bien la corrélation avec une pop en particulier et absent
chez les autres. Souligne les limites de l'approche Tishkoff et
al.~(2007). Convergent adaptation of human lactase persistence. Nature
Genetics. → Exemple canonique d'un variant fortement structuré,
biologiquement causal mais confondu avec la population.

Mathieson et McVean (2012). Differential confounding of GWAS by
population stratification. PLoS Genetics. → Explique pourquoi la
correction peut éliminer de vrais signaux biologiques liés à
l'adaptation locale.

\hypertarget{caractuxe9risation-des-ressources-guxe9nomiques-et-phuxe9notypiques}{%
\section{Caractérisation des ressources génomiques et
phénotypiques}\label{caractuxe9risation-des-ressources-guxe9nomiques-et-phuxe9notypiques}}

La prédiction de phénotypes complexes se heurte à un obstacle majeur :
la structure de population est hautement hiérarchisée chez le peuplier
noir (\emph{Populus nigra})

\hypertarget{etude-de-la-structure-des-populations-de-populus-nigra}{%
\subsection{Etude de la structure des populations de Populus
nigra}\label{etude-de-la-structure-des-populations-de-populus-nigra}}

SNPs et structure de la population : qlq ACP etc etc

\hypertarget{guxe9nuxe9ration-de-phuxe9notypes-de-contruxf4le-traits-nuls}{%
\subsection{Génération de phénotypes de contrôle (traits
nuls)}\label{guxe9nuxe9ration-de-phuxe9notypes-de-contruxf4le-traits-nuls}}

\hypertarget{correction-de-la-structure-de-population-et-de-lapparentement}{%
\section{Correction de la structure de population et de
l'apparentement}\label{correction-de-la-structure-de-population-et-de-lapparentement}}

Justification du modèle \(Q+K\) (Yu \& Price) pour obtenir des résidus
propres :

\hypertarget{impluxe9mentation-du-moduxe8le-mixte-qk}{%
\subsection{Implémentation du modèle mixte
(Q+K)}\label{impluxe9mentation-du-moduxe8le-mixte-qk}}

Pour isoler le signal épistatique du signal polygénique de fond, nous
utilisons un modèle linéaire mixte (LMM) pour déflater le phénotype.

Distinction entre Kinship et PCs Dans notre modèle, nous utilisons deux
niveaux de correction : - \textbf{La Kinship (effet aléatoire) :} Elle
modélise la variance liée à l'apparentement ``fin'' (cousins, frères).
Elle traite les individus comme issus d'une distribution continue. -
\textbf{Les Composantes Principales de la Kinship et la Population (PCs
- effets fixes) :} Elles agissent comme des ``interrupteurs'' puissants
retirant les différences massives entre grandes populations
géographiques.

formule de la kinship d'après Yang et al.~(2011) :

\[K = \frac{ZZ^T}{N}\] avec Z la matrice centrée et réduite de la
matrice de génotypes brute (\(0, 1, 2\)) :

\[z_{ij} = \frac{x_{ij} - 2p_i}{\sqrt{2p_i(1 - p_i)}}\] avec
\[p_i = \frac{\text{Nombre d'allèles de référence}}{2 \times \text{Nombre d'individus}}\]

et le dénominateur : l'écart-type théorique sous l'équilibre de
Hardy-Weinberg. \[\sqrt{2p_i(1 - p_i)}\]

On utilise le facteur 2 car nos individus sont diploïdes. \(2p\)
représente l'espérance du nombre d'allèles au locus \(i\)

\[(ZZ^T)_{jk} = \sum_{i=1}^{N} z_{ij} \times z_{ik}\]

\[(ZZ^T)_{jk} = \sum_{i=1}^{N} \frac{(x_{ij} - 2p_i)}{\sqrt{2p_i(1 - p_i)}} \times \frac{(x_{ik} - 2p_i)}{\sqrt{2p_i(1 - p_i)}}\]

\[K_{jk} = \frac{1}{N} \sum_{i} \frac{(x_{ij} - 2p_i)(x_{ik} - 2p_i)}{2p_i(1 - p_i)}\]

L'utilisation conjointe des PCs (ici les 3 premières) et de la Kinship
garantit que : 1. Le ``gros'' de la structure (histoire évolutive et
géographie) est évacué mathématiquement. 2. La Kinship affine la
correction pour la proximité familiale.

Le MLM classique ``lisse'' la génétique pour éviter les faux positifs en
ajustant les \(p-values\) selon la ressemblance familiale. Cependant, il
suppose que les effets s'additionnent simplement (\(1+1=2\)) et reste
``aveugle'' à l'épistasie (où l'effet du SNP A dépend du SNP B).

En fournissant les résidus au Random Forest, on lui transmet la part du
phénotype que la parenté n'a pas pu expliquer. Si un individu est
beaucoup plus performant que ce que sa ``famille'' laisse prévoir, la RF
cherchera les combinaisons uniques de SNPs (chemins décisionnels)
expliquant ce gain.

Le ``Double Tamisage'' Cette méthode résout le problème de la
colinéarité. Une RF sur phénotype brut ``redécouvrirait'' simplement la
parenté. Sur résidus, chaque point d'importance apporte une
\textbf{information à priori nouvelle}. - \textbf{(LMM) :} Enlève la
structure globale. - \textbf{(RF) :} Cherche les pépites (interactions)
dans ce qui reste.

\hypertarget{extraction-et-validation-des-ruxe9sidus-phuxe9notypiques}{%
\subsection{Extraction et validation des résidus
phénotypiques}\label{extraction-et-validation-des-ruxe9sidus-phuxe9notypiques}}

pour circ 2009 : Variance Génétique (\(\sigma^2_g\)) : u:ID = 0.079

Variance Résiduelle (\(\sigma^2_e\)) : units = 0.234

Héritabilité calculée :
\(h^2 = \frac{0.079}{0.079 + 0.234} \approx \mathbf{0.25}\)

pour angle insertion

calcul de l'héritabilité (\(h^2\)) :

\(\sigma^2_g\) (u:ID) : \(0.182\) \(\sigma^2_e\) (units) : \(0.198\)
\(h^2\) : \(\frac{0.182}{0.182 + 0.198} = \mathbf{0.48}\) Zratio (1.07)
montre que cette estimation reste incertaine statistiquement

\hypertarget{analyse-comparative-des-muxe9thodes-de-scoring-des-snps}{%
\section{Analyse comparative des méthodes de scoring des
SNPs}\label{analyse-comparative-des-muxe9thodes-de-scoring-des-snps}}

\hypertarget{estimation-des-effets-additifs-via-le-moduxe8le-mlmm}{%
\subsection{Estimation des effets additifs via le modèle
MLMM}\label{estimation-des-effets-additifs-via-le-moduxe8le-mlmm}}

L'objectif est d'identifier les effets additifs principaux, considérés
comme les ``piliers'' de l'architecture génétique du caractère.

\textbf{Outils}: MLM (Mixed Linear Model) et FarmCPU (Fixed and Adaptive
Model for Mixed Probability).

\textbf{Principe}: Ces modèles reposent sur l'hypothèse de l'additivité,
où chaque variant contribue de manière indépendante et linéaire à la
valeur phénotypique. Si le MLM s'inscrit dans une vision infinitésimale
(multiplicité de petits effets), FarmCPU utilise une stratégie itérative
pour mieux isoler les QTLs majeurs tout en contrôlant la structure de
population.

\textbf{Sélection}: Extraction du Top K SNPs basée sur la
significativité statistique (\(p\text{-value}\)). Ce ``tamisage''
privilégie les marqueurs présentant un signal robuste et stable sur
l'ensemble de la population étudiée.

\hypertarget{capture-des-effets-non-linuxe9aires-par-random-forest-ranger}{%
\subsection{Capture des effets non linéaires par Random Forest
(Ranger)}\label{capture-des-effets-non-linuxe9aires-par-random-forest-ranger}}

Ce bras vise à capturer les effets fins, les interactions gène x gène
(épistasie) et les effets à seuil que le modèle linéaire échoue à
détecter.

\begin{itemize}
\tightlist
\item
  \textbf{Outils :} Forêt aléatoire (\texttt{ranger}) avec mesure
  d'importance corrigée.
\item
  \textbf{Principe :} En travaillant sur les \textbf{résidus} du modèle
  nul, on force l'algorithme à faire abstraction de la structure de
  population et de l'apparentement moyen pour se concentrer sur les
  ``exceptions à la règle'' (déviations phénotypiques inexpliquées par
  la génétique additive).
\item
  \textbf{Stratégie de ``Feature Subspacing'' :} Pour pallier le
  problème de la haute dimension (\(p = 210\,000\) pour \(n = 199\)),
  nous avons mis en place un protocole d'échantillonnage itératif : 870
  tirages avec remise de sous-ensembles de 5 000 SNPs.
\end{itemize}

\hypertarget{avantages-muxe9thodologiques-du-sous-uxe9chantillonnage-de-snps}{%
\paragraph{Avantages méthodologiques du sous-échantillonnage de SNPs
:}\label{avantages-muxe9thodologiques-du-sous-uxe9chantillonnage-de-snps}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Stabilisation du score d'importance :} Chaque SNP est
  sélectionné en moyenne 20 fois dans des contextes génomiques
  (voisinages de tirage) différents. Le score final d'importance est une
  moyenne pondérée de ces itérations, ce qui permet de lisser le ``biais
  de contexte'' et de stabiliser l'importance statistique de chaque
  marqueur : \[E[Imp] = \frac{1}{N} \sum_{i=1}^{N} Imp_{i}\] où
  \(N \approx 20\) est le nombre de répétitions par SNP.
\end{enumerate}

\textbf{Équité statistique et couverture exhaustive :} Avec 210 000
SNPs, une forêt aléatoire globale nécessiterait un nombre d'arbres
démesuré pour garantir que chaque variable soit testée de manière
significative. Notre approche garantit mathématiquement une couverture
totale du génome. Chaque SNP passe un ``examen'' répété, assurant
qu'aucun variant d'intérêt ne reste dans l'angle mort du modèle par
simple malchance au tirage.

\textbf{Réduction des biais de sélection et robustesse du scoring}

Inspirée par les travaux de \textbf{Strobl et al.~(2007)}, cette
approche par sous-échantillonnage de variables (Feature Subspacing)
limite les biais de sélection inhérents aux algorithmes d'arbres de
décision en haute dimension. Elle transforme la forêt aléatoire d'un
outil de prédiction ``boîte noire'' en un outil de scoring génomique
grâce à plusieurs mécanismes :

\begin{itemize}
\item
  \textbf{Neutralisation du biais de catégorie par l'homogénéité
  d'échelle :} L'un des biais majeurs identifiés par Strobl est la
  tendance des forêts aléatoires à favoriser les variables offrant le
  plus grand nombre de points de coupure (split points). Dans notre
  étude, tous les SNPs sont codés de manière identique (\(0, 1, 2\)).
  Cette homogénéité garantit qu'aucun marqueur n'est favorisé par sa
  structure mathématique ; seule sa capacité intrinsèque à expliquer la
  variance du résidu phénotypique détermine son score.
\item
  \textbf{Décomposition du Déséquilibre de Liaison (LD) par le
  sub-sampling :} En génétique, la corrélation entre SNPs voisins (LD)
  crée une compétition où un ``leader'' statistique peut masquer
  l'importance de ses voisins. En ne présentant que \textasciitilde2\%
  du génome (5 000 SNPs) à chaque tirage, nous réduisons drastiquement
  la probabilité que plusieurs SNPs d'un même bloc de LD soient en
  compétition directe. Cela permet de ``casser'' temporairement ces
  corrélations et d'attribuer un score à chaque SNP de la région
  causale, plutôt que d'écraser les scores des voisins.
\item
  \textbf{Stabilité statistique par l'espérance d'importance :} La
  répétition de l'expérience sur 870 itérations permet de passer d'une
  mesure ponctuelle et potentiellement instable à une \textbf{espérance
  mathématique d'importance} (\(E[Imp]\)). Avec chaque SNP testé en
  moyenne 20 fois dans des voisinages génomiques aléatoires différents,
  le score final est stabilisé et reflète la contribution robuste du
  marqueur :
\end{itemize}

\[E[Imp] \approx \frac{1}{N} \sum_{i=1}^{N} Score_{i}\]

où \(N\) est le nombre de tirages incluant le SNP. Cette convergence
statistique assure que le ``Top K'' final est constitué de variables
ayant prouvé leur importance de manière répétée et équitable,
garantissant la fiabilité biologique de la sélection.

\begin{itemize}
\tightlist
\item
  \textbf{Sélection :} Extraction du Top K SNPs par score d'importance
  moyen.
\end{itemize}

\hypertarget{comportement-des-moduxe8les-de-scoring-face-au-signal-aluxe9atoire}{%
\subsection{Comportement des modèles de scoring face au signal
aléatoire}\label{comportement-des-moduxe8les-de-scoring-face-au-signal-aluxe9atoire}}

\hypertarget{uxe9valuation-de-la-divergence-des-suxe9lections}{%
\subsection{Évaluation de la divergence des
sélections}\label{uxe9valuation-de-la-divergence-des-suxe9lections}}

La mise en place de deux approches méthodologiques distinctes
(\textbf{GWAS} vs \textbf{Random Forest sur résidus}) soulève une
question fondamentale : ces méthodes capturent-elles la même information
biologique via des marqueurs différents (redondance due au déséquilibre
de liaison) ou explorent-elles des architectures génétiques réellement
distinctes ?

Pour répondre à cette interrogation, nous avons déployé une stratégie de
comparaison métrique.

\hypertarget{mesure-de-lindice-de-rand-ajustuxe9-ari}{%
\subsubsection{Mesure de l'indice de Rand ajusté
(ARI)}\label{mesure-de-lindice-de-rand-ajustuxe9-ari}}

Dans un premier temps, nous avons évalué le chevauchement des ``Top
SNPs'' sélectionnés par chaque méthode via l'\textbf{Adjusted Rand Index
(ARI)}.

Bien que classiquement utilisé pour le clustering, l'ARI permet ici de
mesurer la similarité entre les listes de variants priorisés. Les
résultats préliminaires indiquent un ARI proche de zéro entre les
sélections \emph{FarmCPU} et \emph{Random Forest}, suggérant une
divergence quasi totale des cibles moléculaires brutes.

Cependant, en génétique des populations structurées, la distance
physique ou l'identité stricte des marqueurs ne suffit pas. Deux SNPs
différents peuvent porter la même information s'ils sont en fort
\textbf{Déséquilibre de Liaison (LD)}.

\hypertarget{analyse-de-la-distribution-des-scores-par-earth-movers-distance-emd}{%
\subsubsection{Analyse de la distribution des scores par Earth Mover's
Distance
(EMD)}\label{analyse-de-la-distribution-des-scores-par-earth-movers-distance-emd}}

Pour s'affranchir des biais de position et mesurer la véritable distance
biologique entre les signaux, nous avons appliqué l'algorithme de
l'\textbf{Earth Mover's Distance (EMD)}, ou distance de Wasserstein.

Dans cette analyse, au lieu d'une distance physique en paires de bases,
nous avons défini le coût de transport entre deux SNPs \(i\) et \(j\)
comme fonction de leur corrélation génétique :

\[Coût(i, j) = 1 - r^2_{ij}\]

Nous avons normalisé les scores d'importance (RF) et les
\(-\log_{10}(p\text{-values})\) (GWAS) pour qu'ils forment des
distributions de probabilité (somme égale à 1). L'EMD mesure alors
l'effort minimal pour transformer la ``carte d'importance'' du GWAS en
celle de la Random Forest.

\hypertarget{ruxe9sultats-et-interpruxe9tation}{%
\paragraph{Résultats et
Interprétation}\label{ruxe9sultats-et-interpruxe9tation}}

Les calculs d'EMD-LD révèlent une hiérarchie claire dans la divergence
des signaux :

\begin{itemize}
\tightlist
\item
  \textbf{GWAS (FarmCPU) vs MLM classique :} \(EMD \approx 0.02\).

  \begin{itemize}
  \tightlist
  \item
    \emph{Interprétation :} La distance est négligeable. Les deux
    modèles linéaires identifient essentiellement les mêmes blocs
    d'haplotypes. C'est notre contrôle négatif.
  \end{itemize}
\item
  \textbf{GWAS (FarmCPU) vs Random Forest (sur Résidus) :}
  \(EMD \approx 0.64\).

  \begin{itemize}
  \tightlist
  \item
    \emph{Interprétation :} Ce score élevé indique une \textbf{rupture
    haplotypique}. Pour retrouver le signal de la RF à partir du GWAS,
    il faut ``transporter'' la masse d'importance vers des SNPs qui ne
    partagent en moyenne que \textbf{36\%} de corrélation (\(1 - 0.64\))
    avec les signaux linéaires.
  \end{itemize}
\end{itemize}

Cela démontre que la Random Forest ne se contente pas de sélectionner
des ``tags'' alternatifs pour les mêmes QTLs, mais identifie des régions
génomiques indépendantes des découvertes du GWAS.

Cette divergence métrique s'incarne biologiquement dans l'identification
de variants \textbf{``exclusifs''}. En croisant les scores d'importance
avec les matrices de LD, nous avons isolé des SNPs présentant une
importance prédictive majeure (Score \textgreater{} 2000) tout en étant
totalement décorrélés des pics GWAS (\(r^2_{max} < 0.1\)).

Ces résultats mettent en lumière une \textbf{``matière noire''
génétique} : des locus essentiels pour la prédiction phénotypique mais
invisibles pour l'inférence statistique classique.

\hypertarget{limite-et-validation-conceptuelle}{%
\subsubsection{Limite et Validation
Conceptuelle}\label{limite-et-validation-conceptuelle}}

Nous reconnaissons que la \(p\text{-value}\) (inférence de l'effet moyen
additif) et le score d'importance (contribution à l'architecture
prédictive globale) représentent des propriétés statistiques distinctes.

Cependant, l'utilisation de l'EMD sur des distributions normalisées
permet de s'affranchir des échelles de mesure pour se concentrer sur la
\textbf{topographie de l'information}. La divergence observée (\(0.64\))
valide l'hypothèse selon laquelle la supériorité prédictive de la Random
Forest provient de l'exploitation de cette ``matière noire'' --- des
interactions complexes et des effets non-linéaires que le modèle
linéaire, par construction, ne peut percevoir.

\hypertarget{uxe9valuation-des-performances-de-pruxe9diction-guxe9nomique}{%
\section{Évaluation des performances de prédiction
génomique}\label{uxe9valuation-des-performances-de-pruxe9diction-guxe9nomique}}

\hypertarget{validation-de-la-baseline-de-pruxe9diction}{%
\subsection{Validation de la baseline de
prédiction}\label{validation-de-la-baseline-de-pruxe9diction}}

\hypertarget{comparaison-des-capacituxe9s-pruxe9dictives-r2}{%
\subsection{\texorpdfstring{Comparaison des capacités prédictives
(\(R^2\))}{Comparaison des capacités prédictives (R\^{}2)}}\label{comparaison-des-capacituxe9s-pruxe9dictives-r2}}

L'étape finale consiste à fusionner les découvertes des deux bras dans
un modèle unique :

\[Y \sim Ridge(SNP_{GWAS} + SNP_{RF})\] Nous réalisons une intégration
dirigée : - Nous forçons le modèle à considérer les SNPs linéairement
importants (GWAS). - Nous injectons les SNPs porteurs d'information
complexe (RF).

La Ridge Regression réalise l'arbitrage final grâce à sa pénalité
\(L_2\). Contrairement à un XGBoost qui pourrait accorder une importance
démesurée à une interaction par pur hasard statistique (bruit) sur un
faible effectif (\(n=199\)), la Ridge stabilise les coefficients. Si une
interaction trouvée par la RF n'est pas robuste, son coefficient sera
réduit vers zéro, assurant ainsi la généralisation du modèle.

\hypertarget{discussions-et-perspectives}{%
\section{Discussions et
perspectives}\label{discussions-et-perspectives}}



\end{document}
